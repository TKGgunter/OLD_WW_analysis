{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two forest meathod for WW selection ( selection cuts inspired by the CMS Higg &rarr; WW method)\n",
    "\n",
    "Oct. 21 \n",
    "\n",
    "We select WW using a convolution of two random forest. We preform a preselection on the data removing the Z peak, b jets and extra leptons. We performed this analysis on sub-leading lepton pt greater than 10 GeV selection. We find that we an easily recreate and exceed the yield quoted by CMS. \n",
    "\n",
    "Future:\n",
    "\n",
    "Validate RF results in data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading plotting specs...\n",
      "8 or 13 TeV:13TeV\n",
      "unc_mc_process and scales as dictionaries\n",
      "Load MC and Data?False\n",
      "df = pd.concat([df_dy0, df_dy1, df_dy2, df_dy3, df_dy4, df_dy_m_10, df_ww, df_tt_l, df_tt_sl, df_zz_ln, df_wz_ln, df_wz_lq ])\n"
     ]
    }
   ],
   "source": [
    "run ../prep_ana.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data_13TeV/out_Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [ 'process', 'process_decay',\n",
    "        'weight', 'lep1_Charge', 'lep2_Charge', 'lep_Type', 'numbExtraLep',\n",
    "        'mll', 'numb_jets', 'metMod',\n",
    "        'dPhiLL',\n",
    "        'jet1_pt', 'jet2_pt', 'HT', 'numb_BJet', 'jet1_csv',\n",
    "        'METProj_sin', 'met_over_sET','METProj', 'met_phi',\n",
    "        'dPhiLLMET',  'mllMET', 'qT', 'recoil', 'dPhiLLJet', 'dPhiMETJet']\n",
    "\n",
    "df_dy0 = rp.read_root(data_path+\"/dyjetstoll_m-50_complete.root\", columns=columns)\n",
    "df_dy_m_10 = rp.read_root(data_path+\"/dyjetstoll_m-10to50_complete.root\", columns=columns)\n",
    "df_ww = rp.read_root(data_path+\"/ww_complete.root\", columns=columns)\n",
    "df_tt_l = rp.read_root(data_path+\"/ttbar_leptonic_complete.root\", columns=columns)\n",
    "df_tt_sl = rp.read_root(data_path+\"/ttbar_semileptonic_complete.root\", columns=columns)\n",
    "df_t_s = rp.read_root(data_path+\"/t_s-_complete.root\", columns=columns)\n",
    "df_t_t = rp.read_root(data_path+\"/t_t-_complete.root\", columns=columns)\n",
    "df_t_tw = rp.read_root(data_path+\"/t_tw-_complete.root\", columns=columns)\n",
    "#df_tbar_s = rp.read_root(data_path+\"/tbar_s-_complete.root\", columns=columns)\n",
    "df_tbar_t = rp.read_root(data_path+\"/tbar_t-_complete.root\", columns=columns)\n",
    "df_tbar_tw = rp.read_root(data_path+\"/tbar_tw-_complete.root\", columns=columns)\n",
    "df_zz_ln = rp.read_root(data_path+\"/zzjetsto2l2nu_complete.root\", columns=columns)\n",
    "df_zz_lq = rp.read_root(data_path+\"/zzjetsto2l2q_complete.root\", columns=columns)\n",
    "df_wz_lq = rp.read_root(data_path+\"/wzjetsto2l2q_complete.root\", columns=columns)\n",
    "df_wz_ln = rp.read_root(data_path+\"/wzjetsto3lnu_complete.root\", columns=columns)\n",
    "df_w1j = rp.read_root(data_path+\"/w1jetstolnu_complete.root\", columns=columns)\n",
    "df_w2j = rp.read_root(data_path+\"/w2jetstolnu_complete.root\", columns=columns)\n",
    "df_w3j = rp.read_root(data_path+\"/w3jetstolnu_complete.root\", columns=columns)\n",
    "df_w4j = rp.read_root(data_path+\"/w4jetstolnu_complete.root\", columns=columns)\n",
    "\n",
    "df = pd.concat([df_dy0, df_dy_m_10, df_tt_l, df_tt_sl, df_zz_ln, df_zz_lq, df_wz_lq, df_wz_ln, df_w1j, df_w2j, df_w3j, df_w4j, df_ww,\n",
    "               df_tbar_tw, df_tbar_t,df_t_tw,  df_t_t, df_t_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_yields( df ):\n",
    "    for process in df.process.unique():\n",
    "        for decay in df[df.process == process].process_decay.unique():\n",
    "            if decay in scales.keys():\n",
    "                print process, decay, df[(df.process_decay==decay)].shape[0], df[(df.process_decay==decay)].shape[0] * scales[decay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concate processes and preform preselection\n",
    "df_train_test = pre_cuts(df, diff_charge=False)\n",
    "df_train_test = df_train_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_yields( df_train_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187864, 30)\n",
      "(93932, 30)\n",
      "(187864, 30)\n"
     ]
    }
   ],
   "source": [
    "#Select a subset of events that will be used for training and testing\n",
    "\n",
    "#train_DY = df_train_test[df_train_test.process==\"DY\"].sample( frac=0.4 )\n",
    "train_WW = df_train_test[df_train_test.process==\"WW\"].sample( frac=0.4)#n=train_DY.shape[0]*2 )\n",
    "train_DY = df_train_test[df_train_test.process==\"DY\"].sample( n=train_WW.shape[0]*2  )#.45\n",
    "train_TT = df_train_test[df_train_test.process==\"Top\"].sample( n=train_WW.shape[0]*2 )\n",
    "\n",
    "train_fTT = pd.concat( [train_WW, train_TT, ] )\n",
    "train_fDY = pd.concat( [train_WW, train_DY])\n",
    "\n",
    "print train_DY.shape\n",
    "print train_WW.shape\n",
    "print train_TT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281796, 30) (7871806, 30)\n",
      "(140898, 30)\n",
      "(1647917, 30)\n",
      "(5253565, 30)\n"
     ]
    }
   ],
   "source": [
    "test = df_train_test.drop( train_fTT.index )\n",
    "test = test.drop(train_DY.index )\n",
    "print train_fDY.shape, test.shape\n",
    "\n",
    "print test[test.process == \"WW\"].shape\n",
    "print test[test.process == \"DY\"].shape\n",
    "print test[test.process == \"Top\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_da_b = rp.read_root(data_path+\"/muon_2016B_complete.root\", columns=columns)\n",
    "df_da_c = rp.read_root(data_path+\"/muon_2016C_complete.root\", columns=columns)\n",
    "df_da_d = rp.read_root(data_path+\"/muon_2016D_complete.root\", columns=columns)\n",
    "df_da_e = rp.read_root(data_path+\"/muon_2016E_complete.root\", columns=columns)\n",
    "df_da_f = rp.read_root(data_path+\"/muon_2016F_complete.root\", columns=columns)\n",
    "df_da_g = rp.read_root(data_path+\"/muon_2016G_complete.root\", columns=columns)\n",
    "df_da_h = rp.read_root(data_path+\"/muon_2016H_complete.root\", columns=columns)\n",
    "\n",
    "df_da = pd.concat([df_da_b, df_da_c, df_da_d, df_da_e, df_da_f, df_da_g, df_da_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_da_pre = pre_cuts(df_da, diff_charge=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-cut yield check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( df, \"mll\", range=(10,500), scales=scales, bins=50)\n",
    "bins_da = bin_df( df_da, \"mll\", range=(10,500), bins=50 )\n",
    "\n",
    "full_plot( bins_mc, bins_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "bins_mc = bin_df( df_train_test, \"mll\", range=(10,500) , scales=scales, bins=50)\n",
    "bins_da = bin_df( df_da_pre, \"mll\", range=(10,500), bins=50 )\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features, Weights, and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features_fDY = ['numb_jets', 'metMod', 'qT', 'jet1_pt', 'dPhiLLJet', 'dPhiLLMET', 'dPhiMETJet', 'lep_Type']\n",
    "#features_fDY = ['metMod', 'qT', 'jet1_pt', 'dPhiLLMET', 'dPhiMETJet',\\\n",
    "#                'lep_Type', 'METProj_sin_', 'mllMET']\n",
    "features_fDY =['mll', 'lep_Type', 'lep1_pt', 'METProj_sin', 'jet1_pt', 'dPhiLL', 'qT', 'HT', 'dPhiLLMET']#['METProj']\n",
    "#features_fDY = ['numb_jets', 'met_corrected', 'qT', 'jet1_pt', 'dPhiLLJet', 'dPhiLLMET', 'dPhiMETJet', 'lep_Type']\n",
    "#features_fDY = ['numb_jets', 'met_corrected_', 'qT', 'jet1_pt', 'dPhiLLJet', 'dPhiLLMET', 'dPhiMETJet', 'lep_Type']\n",
    "#['numb_jets', 'METProj_sin', 'met_over_sET','METProj_trk_sin', 'qT', 'mllMET', 'recoil', 'jet1_pt', 'dPhiLLJet', 'dPhiLLMET', 'dPhiMETJet', 'lep_Type']\n",
    "features_fTT = ['numb_jets', 'lep2_pt', 'METProj_sin', 'qT', 'mll', 'mllMET', 'metMod', 'dPhiLLMET', 'dPhiLLJet', 'dPhiMETJet', 'dPhiLL', 'HT', 'recoil'] +\\\n",
    "           [ 'lep_Type'] #['METProj' 'jet1_csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create labels \n",
    "#labels TT\n",
    "labels_fTT = np.empty( train_fTT.shape[0] )\n",
    "weights_fTT = np.empty( train_fTT.shape[0])\n",
    "\n",
    "labels_fTT[(train_fTT.process == \"WW\").as_matrix()] = 1\n",
    "labels_fTT[(train_fTT.process == \"Top\").as_matrix()] = 2\n",
    "\n",
    "weights_fTT[(train_fTT.process == \"WW\").as_matrix()] = 1\n",
    "weights_fTT[(train_fTT.process == \"Top\").as_matrix()] = 1\n",
    "\n",
    "#labels DY\n",
    "labels_fDY = np.empty( train_fDY.shape[0] )\n",
    "weights_fDY = np.empty( train_fDY.shape[0])\n",
    "\n",
    "labels_fDY[(train_fDY.process == \"WW\").as_matrix()] = 1\n",
    "labels_fDY[(train_fDY.process == \"DY\").as_matrix()] = 2\n",
    "\n",
    "weights_fDY[(train_fDY.process == \"WW\").as_matrix()] = 1\n",
    "weights_fDY[(train_fDY.process == \"DY\").as_matrix()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTbar training score 0.87171216057\n",
      "Drell Yan training score 0.929218299763\n"
     ]
    }
   ],
   "source": [
    "#Set up random forest for Drell Yan and TTBar selections\n",
    "\n",
    "clf_fTT = RandomForestClassifier(n_estimators=50, n_jobs=-1, min_samples_split=10, max_depth=15, max_features='sqrt')\n",
    "clf_fTT = clf_fTT.fit( np.float32(train_fTT[features_fTT].values) , np.float32(labels_fTT), )#sample_weight=weights_fTT)\n",
    "\n",
    "clf_fDY = RandomForestClassifier(n_estimators=50, n_jobs=-1, min_samples_split=10, max_depth=15, max_features='sqrt')\n",
    "clf_fDY = clf_fDY.fit( np.float32(train_fDY[features_fDY].values) , np.float32(labels_fDY), )#sample_weight=weights_fDY)\n",
    "\n",
    "#Print scores\n",
    "print \"TTbar training score\", clf_fTT.score(np.float32(train_fTT[features_fTT].values), np.float32(labels_fTT), weights_fTT)\n",
    "print \"Drell Yan training score\", clf_fDY.score(np.float32(train_fDY[features_fDY].values), np.float32(labels_fDY), weights_fDY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test = df_train_test.drop( train_fTT.index )\n",
    "#test = test.drop(train_DY.index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict test set Drell Yan and TTbar samples\n",
    "pred_fTT = clf_fTT.predict_proba(np.float32(test[features_fTT].values))\n",
    "test[\"pred_fTT_WW\"] = pred_fTT[:,0]\n",
    "\n",
    "pred_fDY = clf_fDY.predict_proba(np.float32(test[features_fDY].values))\n",
    "test[\"pred_fDY_WW\"] = pred_fDY[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scales_test = {key: scales[key] * ( float(df_train_test[ df_train_test.process_decay == key].shape[0])/ float(test[ test.process_decay == key].shape[0]) ) for key in scales.keys() if key in df_train_test.process_decay.unique() } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in scales.keys():\n",
    "    if key not in scales_test.keys():\n",
    "        scales_test[key] = scales[key]\n",
    "scales_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict on data set\n",
    "features_fDY_da = ['metMod', 'qT', 'jet1_pt', 'dPhiLLMET', 'dPhiMETJet', 'lep_Type', 'METProj_sin', 'mllMET']\n",
    "\n",
    "pred_fTT = clf_fTT.predict_proba(np.float32(df_da_pre[features_fTT].values))\n",
    "df_da_pre[\"pred_fTT_WW\"] = pred_fTT[:,0]\n",
    "\n",
    "pred_fDY = clf_fDY.predict_proba(np.float32(df_da_pre[features_fDY].values))\n",
    "df_da_pre[\"pred_fDY_WW\"] = pred_fDY[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the two results in a set of plots\n",
    "df_da_pre.pred_fDY_WW.hist(bins=50)\n",
    "\n",
    "df_da_pre.pred_fTT_WW.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_da_pre = df_da_pre[ df_da_pre.mll >= 50 ]\n",
    "bins_mc = bin_df( test[ test.mll > 30], \"pred_fDY_WW\", range=(0,1), bins=50, scales=scales_test)\n",
    "bins_da = bin_df( df_da_pre[ df_da_pre.mll > 30], \"pred_fDY_WW\", range=(0,1), bins=50)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\", title=\"fDY\", x_range=(-1,1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( test[ test.mll > 30], \"pred_fTT_WW\", range=(0,1), bins=50, scales=scales_test)\n",
    "bins_da = bin_df( df_da_pre[ df_da_pre.mll > 30], \"pred_fTT_WW\", range=(0,1), bins=50)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\", title=\"fTT\", x_range=(-1,1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_cut = 0.65\n",
    "\n",
    "bins_mc = bin_df( test[ (test.mll > 30) & (test.pred_fTT_WW > rf_cut )], \"pred_fDY_WW\", range=(0,1), bins=50, scales=scales_test)\n",
    "bins_da = bin_df( df_da_pre[ (df_da_pre.mll > 30) & (df_da_pre.pred_fTT_WW > rf_cut)], \"pred_fDY_WW\", range=(0,1), bins=50)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\", title=\"fTT\", x_range=(-1,1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut = 0.35\n",
    "feature_cuts =  (test.pred_fTT_WW > cut) & (test.numbExtraLep == 0) & (test.numb_jets < 2)\n",
    "feature_cuts_diff =( test.lep_Type > 0 ) & feature_cuts\n",
    "feature_cuts_same = (test.lep_Type < 0) & feature_cuts #& (test.METProj_trk_sin > 30)\n",
    "print \"\\tdiff\", \"\\tsame\"\n",
    "for process in scales.keys():\n",
    "    if process in test.process_decay.unique():\n",
    "        print process, test[ (test.process_decay == process) & feature_cuts_diff].shape[0] * scales_test[process],\\\n",
    "    test[ (test.process_decay == process) & feature_cuts_same].shape[0] *scales_test[process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut = 0.8\n",
    "feature_cuts =  (test.pred_fDY_WW > cut) & (test.numbExtraLep == 0) & (test.numb_jets < 2)\n",
    "feature_cuts_diff =( test.lep_Type > 0 ) & feature_cuts\n",
    "feature_cuts_same = (test.lep_Type < 0) & feature_cuts #& (test.METProj_trk_sin > 30)\n",
    "print \"\\tdiff\", \"\\tsame\"\n",
    "for process in scales.keys():\n",
    "    if process in test.process_decay.unique():\n",
    "        print process, test[ (test.process_decay == process) & feature_cuts_diff].shape[0] * scales_test[process],\\\n",
    "    test[ (test.process_decay == process) & feature_cuts_same].shape[0] *scales_test[process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut_tt = 0.65\n",
    "cut_dy = .972\n",
    "feature_cuts =  (test.pred_fTT_WW > cut_tt) & (test.pred_fDY_WW > cut_dy) & (test.numbExtraLep == 0) & (test.mll > 50)\n",
    "feature_cuts_diff =( test.lep_Type > 0 ) & feature_cuts\n",
    "feature_cuts_same = (test.lep_Type < 0) & feature_cuts #& (test.METProj_trk_sin > 30)\n",
    "print \"\\tdiff\", \"\\tsame\"\n",
    "same_yields = 0\n",
    "diff_yields = 0\n",
    "for process in scales.keys():\n",
    "    if process in test.process_decay.unique():\n",
    "        diff_yields_ = test[ (test.process_decay == process) & feature_cuts_diff].shape[0] * scales_test[process]\n",
    "        same_yields_ = test[ (test.process_decay == process) & feature_cuts_same].shape[0] *scales_test[process]\n",
    "        print process, diff_yields_, same_yields_\n",
    "        diff_yields += diff_yields_\n",
    "        same_yields += same_yields_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cuts =  (df_da_pre.pred_fTT_WW > cut_tt) & (df_da_pre.pred_fDY_WW > cut_dy) & (df_da_pre.numbExtraLep == 0) & (df_da_pre.mll > 30)\n",
    "feature_cuts_diff =( df_da_pre.lep_Type > 0 ) & feature_cuts\n",
    "feature_cuts_same = (df_da_pre.lep_Type < 0) & feature_cuts\n",
    "\n",
    "print \"Same:\", df_da_pre[ feature_cuts_same ].shape\n",
    "print \"Diff:\", df_da_pre[ feature_cuts_diff ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Same\", 1953 - same_yields , same_yields\n",
    "print \"Diff\", 6345 - diff_yields - (54+54+189+81+125+75+63+114+36+18+28+33+220), diff_yields\n",
    "472. / 3900."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiForest analysis\n",
    "\n",
    "We wish to formulize our search through the 2 tree phase space. We develope a statistic, yield asymetry, to quantize how the trees perform under a specific combination of cuts. We define this yield as (WW - BKG) / (WW + BKG).  We can compute the CMS yield asymetry from quoted yields as .346. We also define a seperate statistic the normalized uncertainty, defined by  UNC / min_UNC. \n",
    "\n",
    "WW : 4629+1776\n",
    "\n",
    "DY : 206 + 174 \n",
    "\n",
    "TT : 1920 + 810\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def two_tree_process_map( df, pred_names, bins=10, scales=scales):\n",
    "    bins_i = bins\n",
    "    bins_j = bins\n",
    "    if type(bins) == tuple:\n",
    "        bins_i = bins[0]\n",
    "        bins_j = bins[1]\n",
    "    results = {}\n",
    "\n",
    "    for decay in df.process_decay.unique():\n",
    "        ax_i = np.array([ float(i) / float(bins_i) for i in xrange(bins_i)])\n",
    "        ax_j = np.array([ float(j) / float(bins_j) for j in xrange(bins_j)])\n",
    "        a= df[df.process_decay == decay][pred_names[0]].values.reshape( (df[df.process_decay == decay].shape[0], 1) ) > ax_i\n",
    "        b= df[df.process_decay == decay][pred_names[1]].values.reshape( (df[df.process_decay == decay].shape[0], 1) ) > ax_j\n",
    "        ones = np.ones((ax_i.shape[0],df[df.process_decay == decay].shape[0],1), dtype=np.bool)\n",
    "        a_ = ones == a\n",
    "        results_ = a_ & (b.transpose().reshape((ax_i.shape[0],df[df.process_decay == decay].shape[0],1)) == np.ones((df[df.process_decay == decay].shape[0],ax_i.shape[0])))\n",
    "        if decay in scales.keys():\n",
    "            if process in results.keys(): \n",
    "                print \"if \", process,  decay\n",
    "                results[decay] += results_.sum(axis=1) * scales[decay]\n",
    "            else:\n",
    "                print decay\n",
    "                results[decay] = results_.sum(axis=1) * scales[decay]\n",
    "    return results, [ax_i,ax_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yield_asymetry( process_map, df):\n",
    "    results = {}\n",
    "    process_names = [\"WW\", \"DY\", \"Top\"]\n",
    "    for process in process_names:\n",
    "        for decay in process_map[0].keys():\n",
    "            if process in df[ df.process_decay == decay].process.unique():\n",
    "                if process not in results:\n",
    "                    results[process] = process_map[0][decay]\n",
    "                else:\n",
    "                    results[process] += process_map[0][decay]\n",
    "    #results = (process_map[0][\"WW\"] - (process_map[0][\"DY\"] + process_map[0][\"Top\"])) / (process_map[0][\"WW\"] + process_map[0][\"DY\"] + process_map[0][\"Top\"])\n",
    "    results_Numerator = results[\"WW\"] - ( results[\"DY\"] + results[\"Top\"])\n",
    "    results_Denominator = results[\"WW\"] + results[\"DY\"] + results[\"Top\"]\n",
    "    return results_Numerator / results_Denominator, process_map[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_tree_map =two_tree_process_map( test, [\"pred_fTT_WW\", \"pred_fDY_WW\"], bins=50, scales=scales_test)\n",
    "two_tree_yield = yield_asymetry( two_tree_map, test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,9))\n",
    "yield_map = ax.pcolor(two_tree_yield[0])#[35:,10:])\n",
    "plt.colorbar(yield_map)\n",
    "plt.xticks([i for i in range( len(two_tree_yield[1][0])) if i%10==0], [i for e, i in enumerate(two_tree_yield[1][0]) if e%10==0])\n",
    "plt.yticks([i for i in range( len(two_tree_yield[1][1])) if i%10==0], [i for e, i in enumerate(two_tree_yield[1][1]) if e%10==0])\n",
    "plt.xlabel(\"TT RF\")\n",
    "plt.ylabel(\"DY RF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unc_mc_process = {}#{ \"WW\": .05, \"DY\": .03, \"TT\": 0.05, \"ZZ\": 0.1, \"WZ\":.1 }\n",
    "for key in plotting_options.process_decay.unique():\n",
    "  unc_mc_process[key] = plotting_options[plotting_options.process_decay == key][\"unc\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_norm_unc( data ):\n",
    "    coeff = 1./(19.4e3*.15*(3*.108)**2*(data[\"WW\"] /  np.max(data[\"WW\"])))\n",
    "    norm = [ unc_mc_process[process]*(data[process])**0.5 for process in data.keys() if \"WW\" not in process]\n",
    "    sum_norm = np.zeros(data[process].shape)\n",
    "    for ele in norm:\n",
    "        sum_norm += ele**2\n",
    "    return coeff*(sum_norm + unc_mc_process[\"WW\"]/data[\"WW\"])**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_stat_unc( data ):\n",
    "    coeff = 1./(19.4e3*.15*(3*.108)**2*(data[\"WW\"] /  np.max(data[\"WW\"])))\n",
    "    norm = [ scales[process]*(data[process]/scales[process])**0.5 for process in data.keys() if \"WW\" not in process]\n",
    "    \n",
    "    sum_norm = np.zeros(data[process].shape)\n",
    "    for ele in norm:\n",
    "        sum_norm += ele**2 \n",
    "    return coeff*(sum_norm + scales[\"WW\"]/data[\"WW\"] )**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def full_stat( data ):\n",
    "    coeff = 1./(19.7e3*.15*(3*.108)**2*(data[\"WW\"] /  np.max(data[\"WW\"])))\n",
    "    stat = np.zeros(data[\"WW\"].shape)\n",
    "    for i in data.keys():\n",
    "        stat += data[i]\n",
    "        \n",
    "    return coeff*(stat)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unc_map( process_map ):\n",
    "\n",
    "    ax_i = process_map[1][0]\n",
    "    ax_j = process_map[1][1]\n",
    "    \n",
    "    unc_sum = np.power(calc_norm_unc( process_map[0] )**2 + calc_stat_unc( process_map[0] )**2,.5 )#+ full_stat( process_map[0] )**2,.5)\n",
    "    print unc_sum.min()\n",
    "    unc_sum = unc_sum / unc_sum.min()\n",
    "    return unc_sum, [ax_i,ax_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scales_ = scales\n",
    "scales_[\"DY\"] = .5\n",
    "two_tree_unc = unc_map(two_tree_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,9))\n",
    "b = ax.pcolor(two_tree_unc[0], cmap=matplotlib.cm.jet_r )#5:,:45\n",
    "plt.colorbar(b, )#cmap=matplotlib.cm.jet_r)\n",
    "plt.xticks([i for i in range( len(two_tree_unc[1][0])) if i%10==0], [i for e, i in enumerate(two_tree_unc[1][0]) if e%10==0])\n",
    "plt.yticks([i for i in range( len(two_tree_unc[1][1])) if i%10==0], [i for e, i in enumerate(two_tree_unc[1][1]) if e%10==0])\n",
    "plt.xlabel(\"TT RF\")\n",
    "plt.ylabel(\"DY RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_tree_unc =  unc_map(two_tree_map_)#unc_two_tree_heat_map(test, [\"pred_fTT_WW\", \"pred_fDY_WW\"], bins=50, scales={process:scales[process] * float(df[df.process == process].shape[0])/float(test[test.process == process].shape[0]) for process in df.process.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#adsfasdf \n",
    "yield_selection = np.where( (two_tree_yield[0] > .326) & (two_tree_yield[0] < .366))\n",
    "\n",
    "unc_copy = np.copy(two_tree_unc[0])\n",
    "\n",
    "cut_1 = (two_tree_yield[0] < .326) | (two_tree_yield[0] > .366)\n",
    "cut_2 = (two_tree_yield[0] < .28) | (two_tree_yield[0] > .3)\n",
    "cut_3 = (two_tree_yield[0] < .4) | (two_tree_yield[0] > .43)\n",
    "\n",
    "unc_copy[ cut_1 & cut_2 & cut_3 ] = np.nan\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,9))\n",
    "cmap = matplotlib.cm.jet_r\n",
    "cmap.set_bad('white', 1.)\n",
    "\n",
    "\n",
    "\n",
    "masked_array = np.ma.array (unc_copy, mask=np.isnan(unc_copy))\n",
    "\n",
    "f_bar = ax.pcolormesh(masked_array, cmap=cmap, vmax=1.8)\n",
    "\n",
    "\n",
    "plt.xticks([i for i in range( len(two_tree_yield[1][0])) if i%10==0], [i for e, i in enumerate(two_tree_yield[1][0]) if e%10==0])\n",
    "plt.yticks([i for i in range( len(two_tree_yield[1][1])) if i%10==0], [i for e, i in enumerate(two_tree_yield[1][1]) if e%10==0])\n",
    "plt.xlabel(\"TT RF\")\n",
    "plt.ylabel(\"DY RF\")\n",
    "plt.colorbar(f_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection = (unc_copy != np.nan) & (unc_copy <= b_[np.invert(np.isnan(unc_copy))].min()+.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unc_copy[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[0][selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_max_cms = 1.95\n",
    "y_max_f = 1#1.376\n",
    "y_max = max(y_max_cms, y_max_f)+.01\n",
    "\n",
    "plt.plot( a[0][asdf], unc_copy[selection], 'o' )\n",
    "plt.plot( [.34], [y_max_cms], 'ro')#needs to be varified\n",
    "plt.plot([0.34, 0.34], [0.995, y_max], 'r')\n",
    "#plt.plot( [.64], [y_max_f], '*')\n",
    "plt.plot([0.64, 0.64], [0.995, y_max], 'g')\n",
    "\n",
    "plt.ylim([0.995, y_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print two_tree_map[0][\"DY\"][selection]\n",
    "print two_tree_map[0][\"TT\"][selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CMS\n",
    "ww = 1776 + 4629.\n",
    "dy = 206 + 174.\n",
    "tt = 810 + 1920.\n",
    "\n",
    "scales_={process:scales[process] * float(df[df.process == process].shape[0])/float(test[test.process == process].shape[0]) for process in df.process.unique()}\n",
    "\n",
    "ceoff = 1./(19.7e3*.15*(3*.108)**2*(ww /  13531.))\n",
    "cms_unc = ceoff * pow( scales_[\"DY\"]**2 * dy/scales_[\"DY\"] + scales_[\"TT\"]**2 * tt/scales_[\"TT\"]  +\\\n",
    "unc_mc_process[\"DY\"]**2 * dy + unc_mc_process[\"TT\"]**2 * tt, .5)\n",
    "\n",
    "cms_unc/ 0.0717293596874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DiFlavor\n",
    "ww = 1357 + 4588.\n",
    "dy = 285 + 376.\n",
    "tt = 216 + 454.\n",
    "\n",
    "ceoff = 1./(19.7e3*.15*(3*.108)**2*(ww /  13531.))\n",
    "cms_unc = ceoff * pow( scales_[\"DY\"]**2 * dy/scales_[\"DY\"] + scales_[\"TT\"]**2 * tt/scales_[\"TT\"]  +\\\n",
    "unc_mc_process[\"DY\"]**2 * dy + unc_mc_process[\"TT\"]**2 * tt, .5)\n",
    "\n",
    "cms_unc/ 0.253882340528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print two_tree_map[0]['WW'][selection], ww\n",
    "print two_tree_map[0]['DY'][selection], dy\n",
    "print two_tree_map[0]['TT'][selection], tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[ (test.pred_fDY_WW >= .98) & (test.pred_fTT_WW >= .14)].numb_jets.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature distributions post rf cuts\n",
    "\n",
    "Checking things post rf cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_cuts( df ):\n",
    "    f_cuts = (df.pred_fTT_WW > cut_tt) & (df.pred_fDY_WW > cut_dy) & (df.numbExtraLep == 0) & (df.mll > 30)\n",
    "    return df[ f_cuts ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump( {\"clf_fDY\":clf_fDY, \"features_fDY\":features_fDY,\\\n",
    "              \"clf_fTT\":clf_fTT, \"features_fTT\":features_fTT}, \"../RF/Jan_22_fDY_fTT.jbl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END EDNFAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest = {\"clf_fDY\":clf_fDY, \"features_fDY\":features_fDY,\\\n",
    "              \"clf_fTT\":clf_fTT, \"features_fTT\":features_fTT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rf_ana( df, flavor=\"both\", random_forest=random_forest):\n",
    "  \n",
    "  rf_cuts = (df.pred_fTT_WW > .65) & (df.pred_fDY_WW > .972) & (df.mll > 30)\n",
    "  same_cuts = (df.lep_Type < 0) & rf_cuts \n",
    "  diff_cuts =  (df.lep_Type > 0) & rf_cuts\n",
    "\n",
    "\n",
    "  if flavor==\"both\": return pd.concat( [df[same_cuts], df[diff_cuts]] )\n",
    "  elif flavor==\"same\": return df[same_cuts]\n",
    "  elif flavor==\"diff\": return df[diff_cuts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cross_stuff(df_mc, df_data, flavor=\"both\", scales=scales):\n",
    "    lumi = 19.7e3\n",
    "    eff  = .1247 #this had to be changed previously\n",
    "    Br   = (3*.108)**2. \n",
    "    \n",
    "    df_mc_c = df_mc[df_mc.lep1_Charge != df_mc.lep2_Charge]\n",
    "    df_data_c = df_data[df_data.lep1_Charge != df_data.lep2_Charge]\n",
    "    \n",
    "    df_mc_c_s = df_mc[df_mc.lep1_Charge == df_mc.lep2_Charge]\n",
    "    df_data_c_s = df_data[df_data.lep1_Charge == df_data.lep2_Charge]\n",
    "    \n",
    "    N_mc = sum([ rf_ana(df_mc_c[df_mc_c.process_decay == process], flavor=flavor).weight.values.sum()*scales[process] for process in scales.keys() if process not in ['WW', 'W1JetsToLNu','W2JetsToLNu','W3JetsToLNu','W3JetsToLNu'] ])\n",
    "    N_Wjets = rf_ana(df_data_c_s, flavor=flavor).shape[0] -  np.array([ rf_ana(df_mc_c_s[(df_mc_c_s.process_decay == process) ], flavor=flavor).weight.values.sum()*scales[process] for process in scales.keys() if process not in [ 'W1JetsToLNu','W2JetsToLNu','W3JetsToLNu','W3JetsToLNu'] ]).sum()\n",
    "    N_mc += N_Wjets\n",
    "    \n",
    "    N_data = cuts_ana(df_data_c, flavor=flavor).shape[0]\n",
    "    \n",
    "    N_ww_select = cuts_ana(df_mc_c[df_mc_c.process_decay == \"WW\"], flavor=flavor).weight.values.sum()*scales[\"WW\"]\n",
    "    N_ww_tot = df_mc[df_mc.process_decay == \"WW\"].weight.values.sum()*scales[\"WW\"]\n",
    "\n",
    "    ratio_s_t = N_ww_select / N_ww_tot\n",
    "    #print \"MC\", N_mc\n",
    "    #print \"DATA\", N_data\n",
    "    #print N_ww_select / N_ww_tot\n",
    "    #print \"WJ\", N_Wjets\n",
    "    return {\"lumi\": lumi, \"eff\": eff, \"Br\": Br, \"N_mc\": N_mc, \"N_data\": N_data, \"ratio_s_t\": ratio_s_t, \"N_ww_select\":N_ww_select, \"N_Wjets\": N_Wjets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stat_unc_calc(df_mc, df_data, flavor=\"both\", scales=scales):\n",
    "    var = calc_cross_stuff(df_mc, df_data, flavor)\n",
    "    lumi = var[\"lumi\"]\n",
    "    eff = var[\"eff\"]\n",
    "    Br = var[\"Br\"]\n",
    "    N_mc = var[\"N_mc\"]\n",
    "    N_data = var[\"N_data\"]\n",
    "    ratio_s_t = var[\"ratio_s_t\"]\n",
    "    N_ww_select = var[\"N_ww_select\"]\n",
    "    N_Wjets = var[\"N_Wjets\"]\n",
    "    \n",
    "    cuts_mc = {process: rf_ana(df_mc[(df_mc.process_decay == process) & (df_mc.lep1_Charge == df_mc.lep2_Charge)], flavor) for process in scales.keys()} \n",
    "    process_stat_unc = [ (cuts_mc[process].weight.values * cuts_mc[process].weight.values).sum()  * scales[process]**2 for process in cuts_mc.keys() if process not in ['WW', 'W1JetsToLNu','W2JetsToLNu','W3JetsToLNu','W3JetsToLNu']] \n",
    "    \n",
    "    WW_stat_unc = (cuts_mc[\"WW\"].weight.values * cuts_mc[\"WW\"].weight.values).sum() * scales[\"WW\"]**2. * ratio_s_t**2. / N_ww_select**2.\n",
    "    \n",
    "    #print \"Process stat\", process_stat_unc\n",
    "    #print \"WW stat\",WW_stat_unc\n",
    "    return 1. / (lumi * eff * Br * ratio_s_t) * ( N_data + sum(process_stat_unc) + WW_stat_unc + N_Wjets)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sys_unc_calc(df_mc, df_data, flavor=\"both\", scales=scales):\n",
    "    var = calc_cross_stuff(df_mc, df_data, flavor)\n",
    "    lumi = var[\"lumi\"]\n",
    "    eff = var[\"eff\"]\n",
    "    Br = var[\"Br\"]\n",
    "    N_mc = var[\"N_mc\"]\n",
    "    N_data = var[\"N_data\"]\n",
    "    ratio_s_t = var[\"ratio_s_t\"]\n",
    "    N_ww_select = var[\"N_ww_select\"]\n",
    "    N_Wjets = var[\"N_Wjets\"]\n",
    "    \n",
    "    cuts_mc = {process: rf_ana(df_mc[(df_mc.process_decay == process) & (df_mc.lep1_Charge == df_mc.lep2_Charge)], flavor) for process in scales.keys()} \n",
    "    process_sys_unc = [ scales[process]**2. * unc_mc_process[process]**2 * cuts_mc[process].weight.sum()**2. for process in cuts_mc.keys() if process not in ['WW', 'W1JetsToLNu','W2JetsToLNu','W3JetsToLNu','W3JetsToLNu']] \n",
    "\n",
    "    WW_sys_unc = unc_mc_process[\"WW\"]**2 * ratio_s_t**2. / N_ww_select**2.\n",
    "    Wjets_sys_unc = N_Wjets**2. \n",
    "    \n",
    "    return 1. / (lumi * eff * Br * ratio_s_t)  * ( sum(process_sys_unc) +  WW_sys_unc + Wjets_sys_unc)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_calc(df_mc, df_data, flavor=\"both\", scales=scales):\n",
    "    var = calc_cross_stuff(df_mc, df_data, flavor)\n",
    "    lumi = var[\"lumi\"]\n",
    "    eff = var[\"eff\"]\n",
    "    Br = var[\"Br\"]\n",
    "    N_mc = var[\"N_mc\"]\n",
    "    N_data = var[\"N_data\"]\n",
    "    ratio_s_t = var[\"ratio_s_t\"]\n",
    "    N_ww_select = var[\"N_ww_select\"]\n",
    "    N_Wjets = var[\"N_Wjets\"]\n",
    "    \n",
    "    return (N_data - N_mc) / (lumi * eff * Br *ratio_s_t)\n",
    "    #return N_ww_select / (lumi * eff * Br *ratio_s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_ana(df_da_pre, flavor=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "toc": {
   "navigate_menu": false,
   "number_sections": true,
   "sideBar": true,
   "threshold": "4",
   "toc_cell": false,
   "toc_position": {
    "height": "818px",
    "left": "0px",
    "right": "1468px",
    "top": "82px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
