{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest lepton flavor study\n",
    "(Oct 26, 2016)\n",
    "\n",
    "This study was done using the the same, very simliar, set-up and methodology to what was done with TMVA over during 2015-mid2016. There are a few glaring mistakes and over sights which will be noted but not corrected in this study. The issues are outlined below. \n",
    "\n",
    "### Issues \n",
    "\n",
    "There are a few issues to note. First that the original forest was not trained on 1/3 of the mc, but ~ 1/3 of WW and the rest of the same order as the WW.  ( 50,000-WW, 70,000-DY, 33,000-TT ) More importantly when producing yeild tables the entire Monte Carlo dataset set was used, including the portion of the set which had been used for training. What worse is that only ~2/3 of the WW set was avalible. So over 50% of the data set used to test on was also used to train. :( \n",
    "\n",
    "Other things: \n",
    "\n",
    "- At this point in time bagged fraction isn't known to be a tunable parameter.\n",
    "\n",
    "- Sklearn seems to cut a bit more harshly on TT then DY as the yields for TT are abit lower while DY is markedly higher then what's produced by TMVA.\n",
    "\n",
    "- 100 trees were trained for each flavor and for the combined set here.  The TMVA forest held 300 trees.\n",
    "\n",
    "### Future \n",
    "\n",
    "I plan to move away from TMVA.  Before doing so I need to determine why their is such a large difference in the DY yields. I plan on completing the analysis with 1/3 of the MC where the number of DY and TT are weighted such that the weighted sum of each process are the same magnitude.\n",
    "\n",
    "link to that note book: \n",
    "\n",
    "=========================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run ../prep_ana.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_yields( df ):\n",
    "    for process in df.process.unique():\n",
    "        for decay in df[df.process == process].process_decay.unique():\n",
    "            if decay in scales.keys():\n",
    "                print process, decay, df[(df.process_decay==decay)].shape[0], df[(df.process_decay==decay)].shape[0] * scales[decay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concate processes and preform preselection\n",
    "df_train_test = pre_cuts(df)\n",
    "df_train_test = df_train_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_yields( df_train_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select a subset of events that will be used for training and testing\n",
    "\n",
    "#train_DY = df_train_test[df_train_test.process==\"DY\"].sample( frac=0.4 )\n",
    "train_WW = df_train_test[df_train_test.process==\"WW\"].sample( frac=0.4)#n=train_DY.shape[0]*2 )\n",
    "train_DY = df_train_test[df_train_test.process==\"DY\"].sample( n=train_WW.shape[0]*2  )#.45\n",
    "train_TT = df_train_test[df_train_test.process==\"Top\"].sample( n=train_WW.shape[0]*2 )\n",
    "\n",
    "train = pd.concat( [train_WW, train_TT, train_DY] )\n",
    "\n",
    "train_same = train[ train.lep_Type < 0]\n",
    "train_diff = train[ train.lep_Type > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set up test sets\n",
    "\n",
    "test_same = df_train_test[ df_train_test.lep_Type < 0].drop( train_same.index )\n",
    "test_diff = df_train_test[ df_train_test.lep_Type > 0].drop( train_diff.index )\n",
    "\n",
    "scales_test = {key: scales[key] * ( float(df_train_test[ df_train_test.process_decay == key].shape[0])/ float(test_same[ test_same.process_decay == key].shape[0] + test_diff[ test_diff.process_decay == key].shape[0]) ) for key in scales.keys() if key in df_train_test.process_decay.unique() } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_da_a = rp.read_root(data_path+\"/muon_2012A_complete.root\")\n",
    "df_da_b = rp.read_root(data_path+\"/muon_2012B_complete.root\")\n",
    "df_da_c = rp.read_root(data_path+\"/muon_2012C_complete.root\")\n",
    "df_da_d = rp.read_root(data_path+\"/muon_2012D_complete.root\")\n",
    "\n",
    "df_da = pd.concat([df_da_a, df_da_b, df_da_c, df_da_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_da_pre = pre_cuts(df_da)\n",
    "df_da_same = df_da_pre[ df_da_pre.lep_Type < 0]\n",
    "df_da_diff = df_da_pre[ df_da_pre.lep_Type > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['qT',\\\n",
    "            'dPhiLL', 'HT', 'recoil']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create labels \n",
    "#labels same\n",
    "labels_same = np.empty( train_same.shape[0] )\n",
    "weights_same = np.empty( train_same.shape[0])\n",
    "\n",
    "labels_same[(train_same.process == \"WW\").as_matrix()] = 1\n",
    "labels_same[(train_same.process == \"Top\").as_matrix()] = 2\n",
    "labels_same[(train_same.process == \"DY\").as_matrix()] = 2\n",
    "\n",
    "weights_same[(train_same.process == \"WW\").as_matrix()] = 1\n",
    "weights_same[(train_same.process == \"Top\").as_matrix()] = 1\n",
    "weights_same[(train_same.process == \"DY\").as_matrix()] = 1\n",
    "\n",
    "\n",
    "#labels diff\n",
    "labels_diff = np.empty( train_diff.shape[0] )\n",
    "weights_diff = np.empty( train_diff.shape[0])\n",
    "\n",
    "labels_diff[(train_diff.process == \"WW\").as_matrix()] = 1\n",
    "labels_diff[(train_diff.process == \"DY\").as_matrix()] = 2\n",
    "labels_diff[(train_diff.process == \"Top\").as_matrix()] = 2\n",
    "\n",
    "weights_diff[(train_diff.process == \"WW\").as_matrix()] = 1\n",
    "weights_diff[(train_diff.process == \"DY\").as_matrix()] = 1\n",
    "weights_same[(train_same.process == \"Top\").as_matrix()] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different flavor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_d = RandomForestClassifier(n_estimators=50, n_jobs=-1, min_samples_split=10, max_depth=15, max_features='sqrt')\n",
    "clf_s = RandomForestClassifier(n_estimators=50, n_jobs=-1, min_samples_split=10, max_depth=15, max_features='sqrt')\n",
    "#n_estimators=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_d = clf_d.fit( np.float32(train_diff[features].values) , np.float32(labels_diff), sample_weight=weights_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clf_d.score(np.float32(train_diff[features].values), np.float32(labels_diff), weights_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_d = clf_d.predict_proba(np.float32(test_diff[features].values))\n",
    "test_diff[\"pred\"] = pred_d[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_d = clf_d.predict_proba(np.float32(df_da_diff[features].values))\n",
    "df_da_diff[\"pred\"] = pred_d[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( test_diff[ test_diff.mll > 30], \"pred\", range=(0,1), bins=50, scales=scales_test)\n",
    "bins_da = bin_df( df_da_diff[ df_da_diff.mll > 30], \"pred\", range=(0,1), bins=50)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\", title=\"different flavor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Same Flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_s = clf_s.fit( np.float32(train_same[features].values) , np.float32(labels_same), sample_weight=weights_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clf_s.score(np.float32(train_same[features].values), np.float32(labels_same), weights_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_s = clf_s.predict_proba(np.float32(test_same[features].values))\n",
    "test_same[\"pred\"] = pred_s[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_s = clf_s.predict_proba(np.float32(df_da_same[features].values))\n",
    "df_da_same[\"pred\"] = pred_s[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( test_same[ test_same.mll > 30], \"pred\", range=(0,1), bins=50, scales=scales_test)\n",
    "bins_da = bin_df( df_da_same[ df_da_same.mll > 30], \"pred\", range=(0,1), bins=50)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\", title=\"same flavor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( test_same[ test_same.mll > 30], \"mll\", scales=scales_test)\n",
    "bins_da = bin_df( df_da_same[ df_da_same.mll > 30], \"mll\", )\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( test_diff[ test_diff.mll > 30], \"metMod\", scales=scales_test)\n",
    "bins_da = bin_df( df_da_diff[ df_da_diff.mll > 30], \"metMod\",)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## same + different flavors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = clf.fit( np.float32(train[features].values) , np.float32(labels), sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clf.score(np.float32(train[features].values), np.float32(labels), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf.predict_proba(np.float32(df[features].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"pred\"] = pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ df.WW == 1 ].pred.hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "scales = {\"WW\": 19.7e3 * 59.8 /  10000431.0 ,\\\n",
    "          \"DY\": 19.7e3 * 3531.9 / 30459500. ,\\\n",
    "          \"TT\": 19.7e3 * 25.81 / 12011428.,\\\n",
    "          \"ZZ\": 19.7e3 * 9.03 / 9799908.,\\\n",
    "          \"WZ\": 19.7e3 * 1.07 / 2017979., \"WJ\": 1 }\n",
    "\n",
    "\n",
    "for process in scales.keys():\n",
    "    if process in df.keys():\n",
    "        print process, df[ (df[process] == 1) & (df.pred > .96912) & (df.lep_Type > 0)].shape[0] *  scales[process],\\\n",
    "        df[ (df[process] == 1) & (df.pred > .96912) & (df.lep_Type < 0)].shape[0] *  scales[process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Results as of sept 21 \n",
    "\n",
    "### trained seperately:\n",
    "\n",
    "Process:    | WW | DY | TT | ZZ+WZ\n",
    "---         |---| ---|--- |---\n",
    "same flavor |1684|395|71 | 192 \n",
    "diff flavor |3799|661|139 | 220 \n",
    "\n",
    "Significant differences\n",
    "\n",
    "- diff DY 661 vs 106 \n",
    "- diff TT 139 vs 433\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trained together:\n",
    "\n",
    "Process:    | WW | DY | TT | ZZ+WZ\n",
    "---         |---| ---|--- |---\n",
    "same flavor |1057|182|36 | 101 \n",
    "diff flavor |4426|485|178 | 279 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# WW practice selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    a = 1. * df_train_test.METProj_sin.values\n",
    "    a[df_train_test.process.values == \"DY\"] = df_train_test.METProj_sin.values[df_train_test.process.values == \"DY\"] * 1.059\n",
    "    df_train_test[\"METProj_sin\"] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_yields_v2( df ):\n",
    "    tot = 0\n",
    "    for process in df.process.unique():\n",
    "        sum_process = 0\n",
    "        for decay in df[df.process == process].process_decay.unique():\n",
    "            if decay in scales.keys():\n",
    "                #print process, decay, df[(df.process_decay==decay)].shape[0], df[(df.process_decay==decay)].shape[0] * scales[decay]\n",
    "                sum_process += df[(df.process_decay==decay)].shape[0] * scales[decay]\n",
    "        print process, sum_process\n",
    "        tot += sum_process\n",
    "    print \"tot\",tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def WW_same( df ):\n",
    "  initial_cuts = (df.mll > 30 )  & (df.numbExtraLep == 0) & (df.numb_jets <  3) & ( df.metMod > 50 ) & (df.mllMET > 100) & (df.HT < 50) & (df.qT > 35)\n",
    "\n",
    "  basic_df_0j_cuts = initial_cuts & (df.lep_Type < 0) & (df.METProj_sin > 50)\n",
    "  return df[basic_df_0j_cuts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_yields_v2( WW_same(df_train_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( WW_same(df_train_test), \"dPhiLL\",)\n",
    "bins_da = bin_df( WW_same(df_da_pre), \"dPhiLL\",)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\", logy=False, y_range=(0,np.max(bins_da[\"Da\"][0])+50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WW_diff( df ):\n",
    "  initial_cuts = (df.mll > 30 )  & (df.numbExtraLep == 0) & (df.numb_jets <  3) & ( df.metMod > 50 ) & (df.mllMET > 100) & (df.HT < 50) & ( df.metMod < 120 )\n",
    "\n",
    "  basic_df_0j_cuts = initial_cuts & (df.lep_Type > 0) & (df.METProj_sin > 30)\n",
    "  return df[basic_df_0j_cuts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_yields_v2( WW_diff(df_train_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_mc = bin_df( WW_diff(df_train_test), \"metMod\",)\n",
    "bins_da = bin_df( WW_diff(df_da_pre), \"metMod\",)\n",
    "\n",
    "full_plot( bins_mc, bins_da, color=\"color_1\", logy=False, y_range=(0,np.max(bins_da[\"Da\"][0])+50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_cross( df_mc, df_da ):\n",
    "    sum_events = 0\n",
    "    for key in scales:\n",
    "        if key in df_mc.process_decay.unique() and key != 'WW':\n",
    "            sum_events += df_mc[df_mc.process_decay == key].shape[0] * scales[key]\n",
    "    LBrEff = 19.7e3 * (3*.108)**2 *.122\n",
    "    print df_mc[df_mc.process == 'WW'].shape[0] * scales[\"WW\"] / (LBrEff * df_mc[df_mc.process == 'WW'].shape[0] / (df[df.process =='WW'].shape[0]) )\n",
    "    return (df_da.shape[0] - sum_events -217- 447 ) / (LBrEff * df_mc[df_mc.process == 'WW'].shape[0] / (df[df.process =='WW'].shape[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_cross( pd.concat( [WW_diff(df_train_test), WW_same(df_train_test)]), pd.concat([WW_diff(df_da_pre), WW_same(df_da_pre)]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_cross( WW_diff(df_train_test), WW_diff(df_da_pre) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_cross(WW_same(df_train_test), WW_same(df_da_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "189+81+114+63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(831.59 + 2684.7 - 823 - 2213 ) / ( 1031.59 + 2884.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_test.process_decay.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "( 831.59 + 2684.7)/ (19.7e3 * (3*.108)**2 *.122 * 3000 / (df[df.process =='WW'].shape[0]*scales['WW']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#b# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yields_test = process_yields_v3( pd.concat( [WW_diff(df_train_test), WW_same(df_train_test)]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(yields_test.to_html(columns=[\"Process\", \"Same Flavor\", \"Diff Flavor\"], index=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_df_to_html(yields_test, \"another_test.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "toc": {
   "navigate_menu": false,
   "number_sections": true,
   "sideBar": true,
   "threshold": "4",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
